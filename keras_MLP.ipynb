{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating MLP with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a test to creat a MLP with Keras for the Kick Off ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP with keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#data\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "X, y = make_moons(n_samples=1000, noise=0.1, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanjo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8044 - loss: 0.6466\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8474 - loss: 0.6242\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.6063\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8443 - loss: 0.5857\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.5557\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8643 - loss: 0.5262\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8317 - loss: 0.5174\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8594 - loss: 0.4752\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 0.4536\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8828 - loss: 0.4149\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8500 - loss: 0.4015\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 0.3911\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8743 - loss: 0.3524\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8649 - loss: 0.3561\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8526 - loss: 0.3503\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8795 - loss: 0.3153\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8949 - loss: 0.2965\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8759 - loss: 0.3070\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.2954\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8739 - loss: 0.2993\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8850 - loss: 0.2637\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8677 - loss: 0.2953\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8659 - loss: 0.2891\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8784 - loss: 0.2631\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8801 - loss: 0.2729\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.2345\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8826 - loss: 0.2472\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8792 - loss: 0.2595\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8860 - loss: 0.2449\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8883 - loss: 0.2470\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8915 - loss: 0.2307\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8798 - loss: 0.2479\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9037 - loss: 0.2166\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8771 - loss: 0.2407\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8751 - loss: 0.2478\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8750 - loss: 0.2439\n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.2309\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8960 - loss: 0.2187\n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.2145\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.2399\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.2392\n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8865 - loss: 0.2343\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8803 - loss: 0.2326\n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8867 - loss: 0.2243\n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.2306\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8829 - loss: 0.2218\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.2498\n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.2083\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8967 - loss: 0.2225\n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 0.2169\n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8915 - loss: 0.2179\n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8732 - loss: 0.2521\n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8913 - loss: 0.2168\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8781 - loss: 0.2327\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.2141\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8797 - loss: 0.2131\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8702 - loss: 0.2393\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8894 - loss: 0.2284\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8909 - loss: 0.2170\n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8912 - loss: 0.2312\n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.2099\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8960 - loss: 0.2125\n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.1907\n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9012 - loss: 0.2137\n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9032 - loss: 0.1993\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.2067\n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8985 - loss: 0.1910\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.2090\n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.1834\n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8917 - loss: 0.2150\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8919 - loss: 0.2178\n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9021 - loss: 0.2047\n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8977 - loss: 0.2103\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.1967\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9019 - loss: 0.1928\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9067 - loss: 0.2022\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8910 - loss: 0.2156\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.1860\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9176 - loss: 0.1728\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.1841\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9035 - loss: 0.2176\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9199 - loss: 0.1798\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.1866\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.1908\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9108 - loss: 0.1850\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.1735\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9066 - loss: 0.2041\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9090 - loss: 0.1822\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.1877\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.1769\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.1929\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9179 - loss: 0.1713\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9193 - loss: 0.1722\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9116 - loss: 0.1943\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9211 - loss: 0.1812\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9101 - loss: 0.1916\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9132 - loss: 0.1831\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9164 - loss: 0.1949\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9192 - loss: 0.1838\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1498\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9273 - loss: 0.1755  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "#train\n",
    "history = model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "\n",
    "#evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# print('loss:', loss)\n",
    "# print('accuracy:', accuracy)\n",
    "\n",
    "#plot the loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel:\n",
    "    def __init__(self, input_dim, layers, activations, optimizer='adam', learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the CustomModel class.\n",
    "\n",
    "        Parameters:\n",
    "        - input_dim: int, the number of input features.\n",
    "        - layers: list of int, the number of neurons in each layer.\n",
    "        - activations: list of str, the activation function for each layer.\n",
    "        - optimizer: str, the optimizer to use (default is 'adam').\n",
    "        - learning_rate: float, the learning rate for the optimizer (default is 0.001).\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = layers\n",
    "        self.activations = activations\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build the Sequential model based on the specified layers and activations.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Add the first layer with input dimension\n",
    "        model.add(Dense(self.layers[0], input_dim=self.input_dim, activation=self.activations[0]))\n",
    "        \n",
    "        # Add the remaining layers\n",
    "        for neurons, activation in zip(self.layers[1:], self.activations[1:]):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        \n",
    "        # Compile the model\n",
    "        if self.optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Currently only 'adam' optimizer is supported.\")\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=10, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train the model on the provided training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: array-like, the training data.\n",
    "        - y_train: array-like, the training labels.\n",
    "        - epochs: int, the number of epochs to train (default is 10).\n",
    "        - batch_size: int, the batch size for training (default is 32).\n",
    "        \"\"\"\n",
    "        self.history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the provided test data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test: array-like, the test data.\n",
    "        - y_test: array-like, the test labels.\n",
    "        \"\"\"\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the provided data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like, the data to make predictions on.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        \"\"\"\n",
    "        Save the model to a file.\n",
    "\n",
    "        Parameters:\n",
    "        - filename: str, the name of the file to save the model to.\n",
    "        \"\"\"\n",
    "        self.model.save(filename)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        \"\"\"\n",
    "        Load a model from a file.\n",
    "\n",
    "        Parameters:\n",
    "        - filename: str, the name of the file to load the model from.\n",
    "        \"\"\"\n",
    "        from keras.models import load_model\n",
    "        self.model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7294 - loss: 1.5725\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 0.3155\n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8931 - loss: 0.2496\n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.1886\n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.2045\n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.1974\n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9089 - loss: 0.2004\n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9379 - loss: 0.1464\n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.1421\n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9690 - loss: 0.0887\n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.0727\n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0597\n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.0601\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9899 - loss: 0.0380\n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9908 - loss: 0.0305\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9970 - loss: 0.0229\n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0172\n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0170\n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0144\n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0183\n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0111\n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0105\n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0091\n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0100\n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0072\n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0081\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0067\n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0081\n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0081\n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0087   \n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9949 - loss: 0.0085\n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0064   \n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0057\n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0040   \n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0059\n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0028   \n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018   \n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018   \n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018   \n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0028 \n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017   \n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016   \n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.9700e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017   \n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0020   \n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.7871e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0014   \n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019   \n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0020   \n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0030\n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0035   \n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011    \n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.6107e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1666e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.1342e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.3012e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.6928e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.0533e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9043e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.8789e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.0877e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 6.5691e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4908e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.7598e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7735e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.1955e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.7556e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011   \n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.3825e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.7223e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.8828e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 5.4055e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7814e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.9755e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.0300e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.3650e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6883e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0416e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.3995e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0243e-04\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0057     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.996666669845581\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One-hot encode the target arrays\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the model parameters\n",
    "    input_dim = 2  # Number of input features\n",
    "    layers = [32, 12, 10] # The last one is the number of output classes\n",
    "    activations = ['relu', 'relu', 'softmax']\n",
    "\n",
    "    # Create the custom model\n",
    "    custom_model = CustomModel(input_dim, layers, activations)\n",
    "\n",
    "    # Assume X_train, y_train, X_test, y_test are your data\n",
    "    # Train the model\n",
    "    custom_model.train(X_train, y_train_one_hot, epochs=100, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = custom_model.evaluate(X_test, y_test_one_hot)\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "    # Save the model\n",
    "    custom_model.save_model(\"custom_model.h5\")\n",
    "\n",
    "    # Load the model\n",
    "    custom_model.load_model(\"custom_model.h5\")\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = custom_model.predict(X_test)\n",
    "\n",
    "    # plot the loss of the model\n",
    "    plt.plot(custom_model.history.history['loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m96\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m396\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">624</span> (2.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m624\u001b[0m (2.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">622</span> (2.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m622\u001b[0m (2.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
