{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating MLP with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a test to creat a MLP with Keras for the Kick Off ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP with keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#data\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "X, y = make_moons(n_samples=1000, noise=0.1, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8509 - loss: 0.5673\n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.5459 \n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.5210 \n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8429 - loss: 0.4967 \n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.4616 \n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.4688 \n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.4220 \n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8821 - loss: 0.3988 \n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8463 - loss: 0.4205 \n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.3758 \n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8688 - loss: 0.3558 \n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3341 \n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8771 - loss: 0.3259\n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.3272 \n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8912 - loss: 0.2893 \n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.2903 \n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.2990 \n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8798 - loss: 0.2949 \n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.3017 \n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.2763 \n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8834 - loss: 0.2746 \n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2755 \n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2735 \n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8712 - loss: 0.2780 \n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2450 \n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2495 \n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.2430 \n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2364 \n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.2494 \n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8761 - loss: 0.2619 \n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2512 \n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9016 - loss: 0.2388 \n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8685 - loss: 0.2692 \n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2345 \n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.2230 \n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.2198 \n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.2197 \n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.2355 \n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.2210\n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2323 \n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2300 \n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2310 \n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.2102 \n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.2198 \n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.2192 \n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8820 - loss: 0.2260 \n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8962 - loss: 0.2124 \n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8927 - loss: 0.2097 \n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.2220 \n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2079 \n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2209 \n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2057 \n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.2282 \n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.2233 \n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.2083\n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.2132 \n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2067 \n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2094 \n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9020 - loss: 0.1960 \n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.1801 \n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.1858 \n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.2113 \n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.1984 \n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.1812 \n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.1951 \n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.1994 \n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.1947 \n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9308 - loss: 0.1764 \n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.1861 \n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.1916 \n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1702 \n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2076 \n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.1826 \n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.1860\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.1992 \n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9419 - loss: 0.1568 \n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9445 - loss: 0.1658 \n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.1724 \n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1448 \n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9340 - loss: 0.1799 \n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1755 \n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9451 - loss: 0.1605 \n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1446 \n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2038 \n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9407 - loss: 0.1814 \n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1420 \n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9408 - loss: 0.1636 \n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.1723 \n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1604 \n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1629 \n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1675 \n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1415 \n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1720 \n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1680 \n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9633 - loss: 0.1403 \n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9625 - loss: 0.1310 \n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1482 \n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1393 \n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1301 \n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1427 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9589 - loss: 0.1379  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "#train\n",
    "history = model.fit(X_train, y_train, epochs=100, verbose=1)\n",
    "\n",
    "#evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# print('loss:', loss)\n",
    "# print('accuracy:', accuracy)\n",
    "\n",
    "#plot the loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel:\n",
    "    def __init__(self, input_dim, layers, activations, optimizer='adam', learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the CustomModel class.\n",
    "\n",
    "        Parameters:\n",
    "        - input_dim: int, the number of input features.\n",
    "        - layers: list of int, the number of neurons in each layer.\n",
    "        - activations: list of str, the activation function for each layer.\n",
    "        - optimizer: str, the optimizer to use (default is 'adam').\n",
    "        - learning_rate: float, the learning rate for the optimizer (default is 0.001).\n",
    "        \"\"\"\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = layers\n",
    "        self.activations = activations\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build the Sequential model based on the specified layers and activations.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Add the first layer with input dimension\n",
    "        model.add(Dense(self.layers[0], input_dim=self.input_dim, activation=self.activations[0]))\n",
    "        \n",
    "        # Add the remaining layers\n",
    "        for neurons, activation in zip(self.layers[1:], self.activations[1:]):\n",
    "            model.add(Dense(neurons, activation=activation))\n",
    "        \n",
    "        # Compile the model\n",
    "        if self.optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        else:\n",
    "            raise ValueError(\"Currently only 'adam' optimizer is supported.\")\n",
    "        \n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=10, batch_size=32):\n",
    "        \"\"\"\n",
    "        Train the model on the provided training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train: array-like, the training data.\n",
    "        - y_train: array-like, the training labels.\n",
    "        - epochs: int, the number of epochs to train (default is 10).\n",
    "        - batch_size: int, the batch size for training (default is 32).\n",
    "        \"\"\"\n",
    "        self.history = self.model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the provided test data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test: array-like, the test data.\n",
    "        - y_test: array-like, the test labels.\n",
    "        \"\"\"\n",
    "        return self.model.evaluate(X_test, y_test)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on the provided data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: array-like, the data to make predictions on.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        \"\"\"\n",
    "        Save the model to a file.\n",
    "\n",
    "        Parameters:\n",
    "        - filename: str, the name of the file to save the model to.\n",
    "        \"\"\"\n",
    "        self.model.save(filename)\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        \"\"\"\n",
    "        Load a model from a file.\n",
    "\n",
    "        Parameters:\n",
    "        - filename: str, the name of the file to load the model from.\n",
    "        \"\"\"\n",
    "        from keras.models import load_model\n",
    "        self.model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5952 - loss: 1.8085    \n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.3202 \n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.2227 \n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2041 \n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2097 \n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.1740 \n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9408 - loss: 0.1237 \n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.1173 \n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0970 \n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9735 - loss: 0.0670 \n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9888 - loss: 0.0466 \n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0341 \n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0242 \n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0239 \n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0136 \n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0156 \n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0126 \n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0113 \n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0086 \n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0070 \n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0093 \n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0120 \n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0071 \n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0051 \n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0066 \n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0052 \n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0051 \n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0039 \n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0048 \n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0043 \n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0031 \n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0031 \n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029 \n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032     \n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0041 \n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0066 \n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032 \n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021     \n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015     \n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017 \n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0034 \n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0015 \n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016     \n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0033 \n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.4187e-04 \n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.6575e-04 \n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013     \n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9846e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012     \n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0030 \n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011     \n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016     \n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014     \n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1684e-04 \n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.0356e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 8.1603e-04 \n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0065 \n",
      "Epoch 68/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0064 \n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.1995e-04 \n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0027 \n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016     \n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3813e-04 \n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9589e-04 \n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8042e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6338e-04 \n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4077e-04 \n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6299e-04 \n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8763e-04 \n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7265e-04 \n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7720e-04 \n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0265e-04 \n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4180e-04 \n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3537e-04 \n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7977e-04 \n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8847e-04 \n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7757e-04 \n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9141e-04 \n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9652e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0735e-04 \n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9310e-04 \n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3688e-04 \n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3156e-04 \n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0364e-04 \n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9230e-04 \n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5468e-04 \n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7042e-04 \n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7794e-04 \n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0890e-04 \n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1789e-04 \n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4932e-04 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0058      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.996666669845581\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One-hot encode the target arrays\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=10)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the model parameters\n",
    "    input_dim = 2  # Number of input features\n",
    "    layers = [32, 12, 10] # The last one is the number of output classes\n",
    "    activations = ['relu', 'relu', 'softmax']\n",
    "\n",
    "    # Create the custom model\n",
    "    custom_model = CustomModel(input_dim, layers, activations)\n",
    "\n",
    "    # Assume X_train, y_train, X_test, y_test are your data\n",
    "    # Train the model\n",
    "    custom_model.train(X_train, y_train_one_hot, epochs=100, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = custom_model.evaluate(X_test, y_test_one_hot)\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "    # Save the model\n",
    "    custom_model.save_model(\"custom_model.h5\")\n",
    "\n",
    "    # Load the model\n",
    "    custom_model.load_model(\"custom_model.h5\")\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = custom_model.predict(X_test)\n",
    "\n",
    "    # plot the loss of the model\n",
    "    plt.plot(custom_model.history.history['loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
